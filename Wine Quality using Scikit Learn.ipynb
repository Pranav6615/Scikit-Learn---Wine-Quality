{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Scikit-Learn: Machine Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial/notebook is made by :\n",
    "\n",
    "Pranav Vinod Chaudhari (BTech-AIML)\n",
    "\n",
    "Reference : https://www.simplilearn.com/tutorials/python-tutorial/scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Python Scikit-Learn?\n",
    "\n",
    "It’s a simple and efficient tool for data mining and data analysis\n",
    "It is built on NumPy, SciPy, and Matplotlib\n",
    "It’s an open-source, commercially available BSD license"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Can We Achieve Using Python Scikit-Learn?\n",
    "For the most part, users accomplish three primary tasks with scikit-learn:\n",
    "\n",
    "1. Classification\n",
    "Identifying which category an object belongs to.\n",
    "\n",
    "Application: Spam detection\n",
    "\n",
    "2. Regression\n",
    "Predicting a continuous variable based on relevant independent variables.\n",
    "\n",
    "Application: Stock price predictions\n",
    "\n",
    "3. Clustering\n",
    "Automatic grouping of similar objects into different clusters.\n",
    "\n",
    "Application: Customer segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Scikit Data Set?\n",
    "\n",
    "For this tutorial, we will use the wine quality-red data set available on Kaggle, where you can also download the .csv file. Save the file in the same location where your Python file is saved.\n",
    "\n",
    "Scikit-learn provides several in-built data sets for our convenience. You can visit https://scikit-learn.org/stable/datasets/index.html to learn the names of those data sets. Let’s see how to import the widely used iris plant data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains details about the composition of wine, as well as it's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Data Set and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "wine = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s discuss each of these modules one-by-one:\n",
    "\n",
    "NumPy is used for algebraic and numerical calculations\n",
    "We have included pandas for working with data frames\n",
    "The model_selection module helps us to select between different models\n",
    "The preprocessing module gives us the ability to scale and transform our data\n",
    "The RandomForestRegressor is used to compare the performance metrics of our data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have imported the data set from its source and converted that into a pandas DataFrame, let's display a few records from this DataFrame. For this, we will use the head() method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wine = pd.read_csv('winequality-red.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head() method gives us the first five records from the data set.\n",
    "\n",
    "Now, let’s look at the total number of rows and columns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n"
     ]
    }
   ],
   "source": [
    "print(wine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set consists of 1599 samples and 12 features, including our target feature.\n",
    "\n",
    "All features include the following:\n",
    "\n",
    "- quality(target)\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides\n",
    "- free sulfur dioxide\n",
    "- total sulfur dioxide\n",
    "- density\n",
    "- pH\n",
    "- sulfates\n",
    "- alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Sets and Test Sets\n",
    "\n",
    "Splitting the data into training and test sets are vital to estimating your model's performance.\n",
    "\n",
    "A training set is used to test our algorithm to build a model.\n",
    "\n",
    "A testing set is used to test our model to see how accurate our predictions are.\n",
    "\n",
    "Let’s separate our target (y) and our training (x) features, and split them into the train and test sets. We will use the scikit-learn train_test_split() function for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine.quality\n",
    "x = wine.drop('quality', axis=1)\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.1, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "Data preprocessing is the process in which we make the data suitable to be performed over a model with less effort. It is the initial and most important process that enhances the quality of the model.\n",
    "\n",
    "## What is Standardization?\n",
    "Standardization is a technique that is performed as a preprocessing step—before machine learning models are applied—to standardize the range of input representing data features.\n",
    "\n",
    "We will be using Transformer API for preprocessing code, which makes the model performance more realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.85165758e-17  5.80186042e-17  8.76451255e-17  2.34851903e-16\n",
      "  1.08630578e-16 -8.14729336e-17  1.48132606e-17 -3.06566601e-14\n",
      "  1.40664254e-15 -1.77759128e-16  1.25048609e-15]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Transformer API\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "#Applying transformer to training dataPython\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "\n",
    "print(x_train_scaled.mean(axis=0))\n",
    "\n",
    "print(x_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Hyperparameter?\n",
    "\n",
    "- Hyperparameters define the higher-level concepts, such as complexity or capacity to learn\n",
    "\n",
    "\n",
    "- It cannot be learned directly from the data in the standard model training process and needs to be predefined\n",
    "\n",
    "Examples of hyperparameters include: \n",
    "\n",
    "- Learning rate\n",
    "\n",
    "- Number of clusters in clustering algorithms\n",
    "\n",
    "You can see the list of tunable hyperparameters in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False))], 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'randomforestregressor': RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False), 'standardscaler__copy': True, 'standardscaler__with_mean': True, 'standardscaler__with_std': True, 'randomforestregressor__bootstrap': True, 'randomforestregressor__criterion': 'mse', 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__max_leaf_nodes': None, 'randomforestregressor__min_impurity_decrease': 0.0, 'randomforestregressor__min_impurity_split': None, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__min_weight_fraction_leaf': 0.0, 'randomforestregressor__n_estimators': 10, 'randomforestregressor__n_jobs': 1, 'randomforestregressor__oob_score': False, 'randomforestregressor__random_state': None, 'randomforestregressor__verbose': 0, 'randomforestregressor__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#List tunable Hyperparameters\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), RandomForestRegressor(n_estimators=10))\n",
    "print(pipeline.get_params())                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The make_pipeline() function is used to combine a preprocessor with a classifier.\n",
    "\n",
    "Let’s declare the hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare hyperparameters to tune\n",
    "hyperparameters = {'randomforestregressor__max_features' : ['auto' , 'sqrt'],\n",
    "                  'randomforestregressor__max_depth' : [None, 1, 2, 4]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Cross-Validation?\n",
    "\n",
    "Cross-validation is an important evaluation technique used to assess the generalization performance of a machine learning model. To avoid overfitting, the data set is usually divided into N random parts with equal volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...imators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'randomforestregressor__max_features': ['auto', 'sqrt'], 'randomforestregressor__max_depth': [None, 1, 2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross-validation\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=3)\n",
    "#Fit and tune model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV performs the cross-validation across the entire grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Pipeline\n",
    "Now it’s time to evaluate the model performance. For this, we import the metrics we used earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5028356516028893\n",
      "0.3253125\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print (r2_score(y_test, y_pred))\n",
    "print (mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The r2_score function is used to calculate the variance of the dependent variable for the independent variable.\n",
    "\n",
    "Mean_squared_error calculates the average of the square of the errors.\n",
    "\n",
    "To assess if the performance is sufficient, we return to the goal of the model that it was designed for.\n",
    "\n",
    "Do not forget to save the model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py:93: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this Python scikit-learn article, we discussed the basic concepts of scikit-learn. We looked at how to import a data set and its different functions. We went through hyperparameters, preprocessing, and cross-validation techniques. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
